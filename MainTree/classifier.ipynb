{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a1b9c4-4668-494a-b9f8-053b1d3a31c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrecorder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m grabar_audio\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01manalyzer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m analizar_espectro\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m predecir_instrumento\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      9\u001b[0m     archivo \u001b[38;5;241m=\u001b[39m grabar_audio(duracion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Ac_Py\\proyecto-1-grupo-km\\MainTree\\classifier.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# clasificador.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# modelo (YAMNet o similar)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Usaremos TensorFlow Hub para cargar un modelo preentrenado\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# (install tensorflow and tensorflow-hub if not installed)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# clasificador.py\n",
    "# modelo (YAMNet o similar)\n",
    "# Usaremos TensorFlow Hub para cargar un modelo preentrenado\n",
    "# (install tensorflow and tensorflow-hub if not installed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Cargar modelo YAMNet\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "def predecir_instrumento(archivo):\n",
    "    wav_data, sr = sf.read(archivo, dtype=np.float32)\n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "    mean_scores = np.mean(scores, axis=0)\n",
    "\n",
    "    # Cargar etiquetas de AudioSet\n",
    "    class_map_path = tf.keras.utils.get_file(\n",
    "        'yamnet_class_map.csv',\n",
    "        'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv'\n",
    "    )\n",
    "    class_names = [line.split(',')[2].strip() for line in open(class_map_path).readlines()[1:]]\n",
    "    top5_i = np.argsort(mean_scores)[::-1][:5]\n",
    "    print(\"\\nðŸ”Š Posibles instrumentos detectados:\")\n",
    "    for i in top5_i:\n",
    "        print(f\"- {class_names[i]} ({mean_scores[i]:.3f})\")\n",
    "    return class_names[top5_i[0]]\n",
    "\n",
    "# comentar todo con \"ctrl + /\"\n",
    "# Alternativa simple basada en similitud espectral\n",
    "# import numpy as np\n",
    "# from scipy.io import wavfile\n",
    "# import os\n",
    "\n",
    "# def calcular_espectro(archivo):\n",
    "#     \"\"\"Calcula el espectro de magnitud normalizado de un archivo .wav\"\"\"\n",
    "#     fs, data = wavfile.read(archivo)\n",
    "#     data = data.astype(float)\n",
    "#     data = data / np.max(np.abs(data))  # normalizaciÃ³n de amplitud\n",
    "#     N = len(data)\n",
    "#     espectro = np.abs(np.fft.fft(data)[:N//2])\n",
    "#     espectro = espectro / np.sum(espectro)  # normalizaciÃ³n espectral\n",
    "#     return espectro\n",
    "\n",
    "# def similitud_espectral(espectro1, espectro2):\n",
    "#     \"\"\"Calcula la similitud entre dos espectros (1 = idÃ©nticos, 0 = distintos)\"\"\"\n",
    "#     min_len = min(len(espectro1), len(espectro2))\n",
    "#     espectro1 = espectro1[:min_len]\n",
    "#     espectro2 = espectro2[:min_len]\n",
    "#     # correlaciÃ³n normalizada\n",
    "#     return np.dot(espectro1, espectro2) / (np.linalg.norm(espectro1) * np.linalg.norm(espectro2))\n",
    "\n",
    "# def clasificar_instrumento(audio_usuario, carpeta_sonidos=\"sounds\"):\n",
    "#     \"\"\"Compara el audio grabado con la base de sonidos y retorna el mÃ¡s similar\"\"\"\n",
    "#     espectro_usuario = calcular_espectro(audio_usuario)\n",
    "#     similitudes = {}\n",
    "\n",
    "#     for archivo in os.listdir(carpeta_sonidos):\n",
    "#         if archivo.endswith(\".wav\"):\n",
    "#             ruta = os.path.join(carpeta_sonidos, archivo)\n",
    "#             espectro_ref = calcular_espectro(ruta)\n",
    "#             similitud = similitud_espectral(espectro_usuario, espectro_ref)\n",
    "#             similitudes[archivo.replace(\".wav\", \"\")] = similitud\n",
    "\n",
    "#     instrumento_predicho = max(similitudes, key=similitudes.get)\n",
    "\n",
    "#     print(\"\\nðŸŽµ Resultados de similitud espectral:\")\n",
    "#     for inst, score in similitudes.items():\n",
    "#         print(f\"  {inst:<12} â†’ {score:.3f}\")\n",
    "\n",
    "#     print(f\"\\nðŸŽ¯ Instrumento mÃ¡s parecido: {instrumento_predicho.upper()}\")\n",
    "#     return instrumento_predicho"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_k",
   "language": "python",
   "name": "entorno_k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
